{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2, Problem 5\n",
    "\n",
    "In this problem we look at weather and how it impacts trading on the New York stock enchange. Complete this notebook and keep it in a homework 2 repo. Submit the repo link though the blackboard.\n",
    "\n",
    "**You are free to add implmentation or markdown cells to make your notebook clearer!!**\n",
    "\n",
    "## Data:\n",
    "\n",
    "The following two datasets are our focus\n",
    "\n",
    "* Weather data [NOAA-GHCN](https://registry.opendata.aws/noaa-ghcn/)\n",
    "* Stock Exchange Data [Yahoo Finance](https://finance.yahoo.com/quote/%5ENYA/history?ltr=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Download The Weather Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Download a year of weather data.\n",
    "\n",
    "The Raw GHCN files don't have column headers, so we manually add them in. It's safer to at this point read in everything as an object & then parse to the correct type once you extract the variables you're interested in. \n",
    "This information can be found in https://docs.opendata.aws/noaa-ghcn-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import urllib \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask.base import compute\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "import dask.diagnostics as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using Dask for the lazy evaluation properties (it will only try to run the computations at the end, hopefully after the data has been filtered down) because the dataset is very large. We set the storage options to `anon=True` because this data is public. Otherwise this kwarg is where we'd pass in the AWS authorization keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Let's load in the data for 1992\n",
    "YEAR = 1992\n",
    "\n",
    "names = ['ID', 'DATE', 'ELEMENT', 'DATA_VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG', 'OBS-TIME']\n",
    "ds = dd.read_csv(f's3://noaa-ghcn-pds/csv/{YEAR}.csv', storage_options={'anon':True},  names=names, memory_map=False, \n",
    "                  dtype={'DATA_VALUE':'object'}, parse_dates=['DATE', 'OBS-TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'DATE', 'ELEMENT', 'DATA_VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG',\n",
      "       'OBS-TIME'],\n",
      "      dtype='object')\n",
      "ID                    object\n",
      "DATE          datetime64[ns]\n",
      "ELEMENT               object\n",
      "DATA_VALUE            object\n",
      "M-FLAG                object\n",
      "Q-FLAG                object\n",
      "S-FLAG                object\n",
      "OBS-TIME              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# You can check the data\n",
    "print(ds.columns)\n",
    "print(ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>DATA_VALUE</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       DATE ELEMENT DATA_VALUE M-FLAG Q-FLAG S-FLAG OBS-TIME\n",
       "0  CA002303986 1992-01-01    TMAX        -70    NaN    NaN      C      nan\n",
       "1  CA002303986 1992-01-01    TMIN       -240    NaN    NaN      C      nan\n",
       "2  CA002303986 1992-01-01    PRCP          4    NaN    NaN      C      nan\n",
       "3  CA002303986 1992-01-01    SNOW          4    NaN    NaN      C      nan\n",
       "4  CA002303986 1992-01-01    SNWD        420    NaN    NaN      C      nan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first few rows\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to parse out the station ID list. We are using [pandas.read_fwf](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_fwf.html#pandas.read_fwf) because this file is a fixed format width table rather than a csv file. \n",
    "We explicitly pass in the extents of the fixed width field because Pandas has trouble inferring what belongs in the `STATE` column versus in the `NAME` column. We obtained these extents from the readme https://docs.opendata.aws/noaa-ghcn-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {column name:extents of the fixed-width fields}\n",
    "columns = {\"ID\": (0,11), \"LATITUDE\": (12, 20), \"LONGITUDE\": (21, 30), \"ELEVATION\": (31, 37),\"STATE\": (38, 40),\n",
    "           \"NAME\": (41, 71), \"GSN FLAG\": (72, 75), \"HCN/CRN FLAG\": (76, 79),\"WMO ID\": (80, 85)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_fwf(\"http://noaa-ghcn-pds.s3.amazonaws.com/ghcnd-stations.txt\", \n",
    "                    colspecs=list(columns.values()), names=list(columns.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>GSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  LATITUDE  LONGITUDE  ELEVATION STATE                   NAME  \\\n",
       "0  ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
       "1  ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
       "2  AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
       "3  AEM00041194   25.2550    55.3640       10.4   NaN             DUBAI INTL   \n",
       "4  AEM00041217   24.4330    54.6510       26.8   NaN         ABU DHABI INTL   \n",
       "\n",
       "  GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "0      NaN          NaN      NaN  \n",
       "1      NaN          NaN      NaN  \n",
       "2      GSN          NaN  41196.0  \n",
       "3      NaN          NaN  41194.0  \n",
       "4      NaN          NaN  41217.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73674</th>\n",
       "      <td>US1NJAT0001</td>\n",
       "      <td>39.5483</td>\n",
       "      <td>-74.8671</td>\n",
       "      <td>31.4</td>\n",
       "      <td>NJ</td>\n",
       "      <td>BUENA VISTA TWP 2.6 NNE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73675</th>\n",
       "      <td>US1NJAT0002</td>\n",
       "      <td>39.5565</td>\n",
       "      <td>-74.8048</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>FOLSOM 3.2 SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73676</th>\n",
       "      <td>US1NJAT0003</td>\n",
       "      <td>39.4747</td>\n",
       "      <td>-74.7107</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NJ</td>\n",
       "      <td>HAMILTON TWP 2.1 SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73677</th>\n",
       "      <td>US1NJAT0005</td>\n",
       "      <td>39.6404</td>\n",
       "      <td>-74.8261</td>\n",
       "      <td>29.9</td>\n",
       "      <td>NJ</td>\n",
       "      <td>HAMMONTON 3.3 WSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73678</th>\n",
       "      <td>US1NJAT0009</td>\n",
       "      <td>39.3346</td>\n",
       "      <td>-74.5759</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NJ</td>\n",
       "      <td>LINWOOD 0.7 SSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "73674  US1NJAT0001   39.5483   -74.8671       31.4    NJ   \n",
       "73675  US1NJAT0002   39.5565   -74.8048       14.0    NJ   \n",
       "73676  US1NJAT0003   39.4747   -74.7107        5.5    NJ   \n",
       "73677  US1NJAT0005   39.6404   -74.8261       29.9    NJ   \n",
       "73678  US1NJAT0009   39.3346   -74.5759        5.8    NJ   \n",
       "\n",
       "                          NAME GSN FLAG HCN/CRN FLAG  WMO ID  \n",
       "73674  BUENA VISTA TWP 2.6 NNE      NaN          NaN     NaN  \n",
       "73675            FOLSOM 3.2 SE      NaN          NaN     NaN  \n",
       "73676      HAMILTON TWP 2.1 SE      NaN          NaN     NaN  \n",
       "73677        HAMMONTON 3.3 WSW      NaN          NaN     NaN  \n",
       "73678          LINWOOD 0.7 SSW      NaN          NaN     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You should be looking for those in the New York area like Central Park, JFK, LGA and Newark airport.\n",
    "NYNJ = df[df['STATE'].isin(['NY', 'NJ'])]\n",
    "NYNJ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central Park is coded in shorthand, so we used the NOAA web portal to look up the correct ID\n",
    "https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094728/detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114226</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>40.7789</td>\n",
       "      <td>-73.9692</td>\n",
       "      <td>39.6</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK CNTRL PK TWR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>72506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "114226  USW00094728   40.7789   -73.9692       39.6    NY   \n",
       "\n",
       "                         NAME GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "114226  NEW YORK CNTRL PK TWR      NaN          HCN  72506.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYNJ[NYNJ['ID'].str.contains('USW00094728')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100219</th>\n",
       "      <td>USC00305840</td>\n",
       "      <td>43.1139</td>\n",
       "      <td>-78.9353</td>\n",
       "      <td>179.2</td>\n",
       "      <td>NY</td>\n",
       "      <td>NIAGARA FALLS INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112764</th>\n",
       "      <td>USW00004724</td>\n",
       "      <td>43.1072</td>\n",
       "      <td>-78.9453</td>\n",
       "      <td>178.3</td>\n",
       "      <td>NY</td>\n",
       "      <td>NIAGARA FALLS INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112769</th>\n",
       "      <td>USW00004742</td>\n",
       "      <td>44.6500</td>\n",
       "      <td>-73.4667</td>\n",
       "      <td>71.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>PLATTSBURGH INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112775</th>\n",
       "      <td>USW00004781</td>\n",
       "      <td>40.7939</td>\n",
       "      <td>-73.1017</td>\n",
       "      <td>25.6</td>\n",
       "      <td>NY</td>\n",
       "      <td>ISLIP LI MACARTHUR AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112779</th>\n",
       "      <td>USW00004789</td>\n",
       "      <td>41.5092</td>\n",
       "      <td>-74.2650</td>\n",
       "      <td>111.3</td>\n",
       "      <td>NY</td>\n",
       "      <td>MONTGOMERY ORANGE AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "100219  USC00305840   43.1139   -78.9353      179.2    NY   \n",
       "112764  USW00004724   43.1072   -78.9453      178.3    NY   \n",
       "112769  USW00004742   44.6500   -73.4667       71.9    NY   \n",
       "112775  USW00004781   40.7939   -73.1017       25.6    NY   \n",
       "112779  USW00004789   41.5092   -74.2650      111.3    NY   \n",
       "\n",
       "                         NAME GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "100219  NIAGARA FALLS INTL AP      NaN          NaN      NaN  \n",
       "112764  NIAGARA FALLS INTL AP      NaN          NaN      NaN  \n",
       "112769    PLATTSBURGH INTL AP      NaN          NaN      NaN  \n",
       "112775  ISLIP LI MACARTHUR AP      NaN          NaN  72505.0  \n",
       "112779   MONTGOMERY ORANGE AP      NaN          NaN      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Airports + Central Park\n",
    "apcp = NYNJ[NYNJ['NAME'].str.endswith('AP') | NYNJ['ID'].str.contains('USW00094728')]\n",
    "apcp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're interested in is the IDs, which we will use for our dataset to obtain only the stations of interest. We are going to join our two dataframes on the ID column so that we have all the information in every row.  We are removing the flags since they have neither computational nor necessary identification information. \n",
    "\n",
    "we do not use `.compute()` to resolve the computation because it's better to hold off until the completetion of feature selection and engineering described below. If you'd like a fully computed dataframe, the code is \n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyds = ds.merge(apcp[['ID', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'STATE', 'NAME']], on='ID').compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>DATA_VALUE</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       DATE ELEMENT DATA_VALUE M-FLAG Q-FLAG S-FLAG OBS-TIME  \\\n",
       "0  USW00094790 1992-01-01    TMAX         61    NaN    NaN      0     2400   \n",
       "1  USW00094790 1992-01-01    TMIN       -133    NaN    NaN      0     2400   \n",
       "2  USW00094790 1992-01-01    PRCP          0    NaN    NaN      0     2400   \n",
       "3  USW00094790 1992-01-01    SNOW          0    NaN    NaN      0      nan   \n",
       "4  USW00094790 1992-01-01    SNWD          0    NaN    NaN      0      nan   \n",
       "\n",
       "   LATITUDE  LONGITUDE  ELEVATION STATE               NAME  \n",
       "0   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "1   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "2   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "3   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "4   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 2: Downoad Stock Price Data\n",
    "\n",
    "Here the idea is to get the finance data from Yahoo finace.  It's already the right date range in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "finance_df = pd.read_csv(\"https://query1.finance.yahoo.com/v7/finance/download/%5ENYA?period1=694224000&period2=725760000&interval=1d&events=history\")\n",
    "finance_df = finance_df.rename(columns={\"Date\": \"DATE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>2435.659912</td>\n",
       "      <td>2435.659912</td>\n",
       "      <td>2435.659912</td>\n",
       "      <td>2435.659912</td>\n",
       "      <td>2435.659912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>2430.370117</td>\n",
       "      <td>2430.370117</td>\n",
       "      <td>2430.370117</td>\n",
       "      <td>2430.370117</td>\n",
       "      <td>2430.370117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>2428.679932</td>\n",
       "      <td>2428.679932</td>\n",
       "      <td>2428.679932</td>\n",
       "      <td>2428.679932</td>\n",
       "      <td>2428.679932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>2434.389893</td>\n",
       "      <td>2434.389893</td>\n",
       "      <td>2434.389893</td>\n",
       "      <td>2434.389893</td>\n",
       "      <td>2434.389893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE         Open         High          Low        Close  \\\n",
       "0  1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "1  1992-01-03  2435.659912  2435.659912  2435.659912  2435.659912   \n",
       "2  1992-01-06  2430.370117  2430.370117  2430.370117  2430.370117   \n",
       "3  1992-01-07  2428.679932  2428.679932  2428.679932  2428.679932   \n",
       "4  1992-01-08  2434.389893  2434.389893  2434.389893  2434.389893   \n",
       "\n",
       "     Adj Close  Volume  \n",
       "0  2423.179932       0  \n",
       "1  2435.659912       0  \n",
       "2  2430.370117       0  \n",
       "3  2428.679932       0  \n",
       "4  2434.389893       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do an inner join for the dates from the financial dataset and the new york weather dataset, to get all your features ready, please do that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your join on dates goes here:\n",
    "#ny_df = nyds.compute()\n",
    "ny_df = nyds\n",
    "ny_df[\"DATE\"] = pd.to_datetime(ny_df[\"DATE\"])\n",
    "finance_df[\"DATE\"] = pd.to_datetime(finance_df[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>DATA_VALUE</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       DATE ELEMENT DATA_VALUE M-FLAG Q-FLAG S-FLAG OBS-TIME  \\\n",
       "0  USW00094790 1992-01-02    TMAX         22    NaN    NaN      0     2400   \n",
       "1  USW00094790 1992-01-02    TMIN        -94    NaN    NaN      0     2400   \n",
       "2  USW00094790 1992-01-02    PRCP          0    NaN    NaN      0     2400   \n",
       "3  USW00094790 1992-01-02    SNOW          0    NaN    NaN      0      nan   \n",
       "4  USW00094790 1992-01-02    SNWD          0    NaN    NaN      0      nan   \n",
       "\n",
       "   LATITUDE  LONGITUDE  ELEVATION STATE               NAME         Open  \\\n",
       "0   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  2423.179932   \n",
       "1   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  2423.179932   \n",
       "2   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  2423.179932   \n",
       "3   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  2423.179932   \n",
       "4   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  2423.179932   \n",
       "\n",
       "          High          Low        Close    Adj Close  Volume  \n",
       "0  2423.179932  2423.179932  2423.179932  2423.179932       0  \n",
       "1  2423.179932  2423.179932  2423.179932  2423.179932       0  \n",
       "2  2423.179932  2423.179932  2423.179932  2423.179932       0  \n",
       "3  2423.179932  2423.179932  2423.179932  2423.179932       0  \n",
       "4  2423.179932  2423.179932  2423.179932  2423.179932       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = ny_df.merge(finance_df, on='DATE')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(['M-FLAG','Q-FLAG','S-FLAG','OBS-TIME'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TMAX', 'TMIN', 'PRCP', 'SNOW', 'SNWD', 'TOBS', 'WT01', 'FMTM',\n",
       "       'PGTM', 'TSUN', 'WDF1', 'WDFG', 'WSF1', 'WSFG', 'ACMH', 'ACSH',\n",
       "       'AWND', 'WT08', 'WT16', 'WT14', 'WT06', 'WT15', 'WT18', 'WT04',\n",
       "       'WT17', 'WT02', 'WT03', 'WT05', 'WT09', 'WESD', 'WT22', 'WT11'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['DATA_VALUE'] = pd.to_numeric(final_df['DATA_VALUE'])\n",
    "final_df['ELEMENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()\n",
    "nyc_weather_df = final_df[(final_df['ELEMENT'] == 'PRCP') | (final_df['ELEMENT'] == 'SNOW') | (final_df['ELEMENT'] == 'SNWD') \n",
    "                    | (final_df['ELEMENT'] == 'WT09') | (final_df['ELEMENT'] == 'WT07') |(final_df['ELEMENT'] == 'WT11')\n",
    "                    | (final_df['ELEMENT'] == 'WT14') |(final_df['ELEMENT'] == 'WT16')|(final_df['ELEMENT'] == 'WT17')\n",
    "                    | (final_df['ELEMENT'] == 'WT04')|(final_df['ELEMENT'] == 'WT05') | (final_df['ELEMENT'] == 'WT18')]\n",
    "nyc_weather_df = pd.pivot_table(nyc_weather_df, values='DATA_VALUE', index=['DATE'], columns=['ELEMENT'],fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ELEMENT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-01-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.941176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-03</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.470588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-06</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-07</th>\n",
       "      <td>2.294118</td>\n",
       "      <td>2.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-08</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ELEMENT         PRCP      SNOW      SNWD  WT04  WT05  WT09  WT11  WT14  WT16  \\\n",
       "DATE                                                                           \n",
       "1992-01-02  0.000000  0.000000  8.941176     0     0     0     0     1     1   \n",
       "1992-01-03  0.294118  0.000000  7.470588     0     0     0     0     1     1   \n",
       "1992-01-06  0.294118  0.000000  0.000000     0     0     0     0     1     1   \n",
       "1992-01-07  2.294118  2.294118  0.000000     1     0     0     0     1     1   \n",
       "1992-01-08  0.176471  0.176471  0.000000     0     0     0     0     0     0   \n",
       "\n",
       "ELEMENT     WT17  WT18  \n",
       "DATE                    \n",
       "1992-01-02     0     0  \n",
       "1992-01-03     0     0  \n",
       "1992-01-06     0     1  \n",
       "1992-01-07     0     1  \n",
       "1992-01-08     0     1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_weather_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_weather_df[\"SNOW\"] = nyc_weather_df[\"SNOW\"].astype('int')\n",
    "nyc_weather_df[\"PRCP\"] = nyc_weather_df[\"PRCP\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>1992-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>1992-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>1992-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>1992-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>1992-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close       DATE\n",
       "0  0.465631  0.465631  0.465631  0.465631   0.465631 1992-01-02\n",
       "1  0.514483  0.514483  0.514483  0.514483   0.514483 1992-01-03\n",
       "2  0.493777  0.493777  0.493777  0.493777   0.493777 1992-01-06\n",
       "3  0.487160  0.487160  0.487160  0.487160   0.487160 1992-01-07\n",
       "4  0.509512  0.509512  0.509512  0.509512   0.509512 1992-01-08"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "cols = ['Open','High','Low','Close','Adj Close']\n",
    "x = finance_df[['Open','High','Low','Close','Adj Close']].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "finance_df_norm = pd.DataFrame(x_scaled, columns=cols)\n",
    "finance_df_norm['DATE'] = finance_df[\"DATE\"]\n",
    "finance_df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge fincial data and stock weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.941176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.470588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close  Adj Close       DATE  PRCP  SNOW  \\\n",
       "0  0.465631  0.465631  0.465631  0.465631   0.465631 1992-01-02     0     0   \n",
       "1  0.514483  0.514483  0.514483  0.514483   0.514483 1992-01-03     0     0   \n",
       "2  0.493777  0.493777  0.493777  0.493777   0.493777 1992-01-06     0     0   \n",
       "3  0.487160  0.487160  0.487160  0.487160   0.487160 1992-01-07     2     2   \n",
       "4  0.509512  0.509512  0.509512  0.509512   0.509512 1992-01-08     0     0   \n",
       "\n",
       "       SNWD  WT04  WT05  WT09  WT11  WT14  WT16  WT17  WT18  \n",
       "0  8.941176     0     0     0     0     1     1     0     0  \n",
       "1  7.470588     0     0     0     0     1     1     0     0  \n",
       "2  0.000000     0     0     0     0     1     1     0     1  \n",
       "3  0.000000     1     0     0     0     1     1     0     1  \n",
       "4  0.000000     0     0     0     0     0     0     0     1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_weather_df = pd.merge(finance_df_norm, nyc_weather_df, on='DATE')\n",
    "stock_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ELEMENT</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT09</th>\n",
       "      <th>WT11</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.941176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.470588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ELEMENT     PRCP  SNOW      SNWD  WT04  WT05  WT09  WT11  WT14  WT16  WT17  \\\n",
       "DATE                                                                         \n",
       "1992-01-02     0     0  8.941176     0     0     0     0     1     1     0   \n",
       "1992-01-03     0     0  7.470588     0     0     0     0     1     1     0   \n",
       "1992-01-06     0     0  0.000000     0     0     0     0     1     1     0   \n",
       "1992-01-07     1     1  0.000000     1     0     0     0     1     1     0   \n",
       "1992-01-08     0     0  0.000000     0     0     0     0     0     0     0   \n",
       "\n",
       "ELEMENT     WT18  \n",
       "DATE              \n",
       "1992-01-02     0  \n",
       "1992-01-03     0  \n",
       "1992-01-06     1  \n",
       "1992-01-07     1  \n",
       "1992-01-08     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_weather_df[\"PRCP\"] = np.array(nyc_weather_df[\"PRCP\"])\n",
    "nyc_weather_df[\"PRCP\"] = np.where(nyc_weather_df[\"PRCP\"]>0,1,0)\n",
    "nyc_weather_df[\"SNOW\"] = np.array(nyc_weather_df[\"SNOW\"])\n",
    "nyc_weather_df[\"SNOW\"] = np.where(nyc_weather_df[\"SNOW\"]>0,1,0)\n",
    "nyc_weather_df[\"PRCP\"] = pd.Series(nyc_weather_df[\"PRCP\"])\n",
    "nyc_weather_df[\"SNOW\"] = pd.Series(nyc_weather_df[\"SNOW\"])\n",
    "nyc_weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 3: Creating and Selecting Variables\n",
    "\n",
    "Pull out and encode the various variables listed below and set up these varaibles at least initially in a pandas data frame.\n",
    "\n",
    "### Weather variables\n",
    "\n",
    "* raining:\n",
    "    - 0 - wasn't raining\n",
    "    - 1 - was raining\n",
    "* rain intensity:\n",
    "    - 0 -low\n",
    "    - 1 - medium\n",
    "    - 2 - high\n",
    "* rain duration in hours\n",
    "* snowing:\n",
    "    - 0 - wasn't snowing\n",
    "    - 1 - was snowing\n",
    "* snow intensity:\n",
    "    - 0 - low\n",
    "    1 - medium\n",
    "    2 - high\n",
    "* snow duration in hours\n",
    "* windy:\n",
    "    - 0 - low\n",
    "    - 1 - medium\n",
    "    - 2 - high\n",
    "\n",
    "### Market Variables \n",
    "\n",
    "* Market Open\n",
    "* Market Close\n",
    "* Market High\n",
    "* Market Low\n",
    "* Market Volume\n",
    "\n",
    "\n",
    "Make sure you have aligned the data by date in a pandas data frame. Show the counts and the summary stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_weather_df['Rain_intensity'] = pd.Series(0, index=nyc_weather_df.index)\n",
    "nyc_weather_df['Snow_intensity'] = pd.Series(0, index=nyc_weather_df.index)\n",
    "nyc_weather_df['Wind_intensity'] = pd.Series(0, index=nyc_weather_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_weather_df[\"Rain_intensity\"] = nyc_weather_df.apply(lambda row : 2 if row['WT17'] == 1 else (1 if row['WT16'] == 1 else 0), axis=1)\n",
    "nyc_weather_df[\"Snow_intensity\"] = nyc_weather_df.apply(lambda row : 2 if row['WT18'] == 1 else (1 if row['WT05'] == 1 else 0), axis=1)\n",
    "nyc_weather_df[\"Wind_intensity\"] = nyc_weather_df.apply(lambda row : 0 if row['WT09'] == 1 else (2 if row['WT11'] == 1 else 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_weather_df = nyc_weather_df.drop(['SNWD', 'WT04', 'WT05', 'WT09', 'WT11', 'WT14', 'WT16',\n",
    "       'WT17', 'WT18'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>Rain_intensity</th>\n",
       "      <th>Snow_intensity</th>\n",
       "      <th>Wind_intensity</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  PRCP  SNOW  Rain_intensity  Snow_intensity  Wind_intensity  \\\n",
       "0 1992-01-02     0     0               1               0               1   \n",
       "1 1992-01-03     0     0               1               0               1   \n",
       "2 1992-01-06     0     0               1               2               1   \n",
       "3 1992-01-07     1     1               1               2               1   \n",
       "4 1992-01-08     0     0               0               2               1   \n",
       "\n",
       "       Open      High       Low     Close  Adj Close  \n",
       "0  0.465631  0.465631  0.465631  0.465631   0.465631  \n",
       "1  0.514483  0.514483  0.514483  0.514483   0.514483  \n",
       "2  0.493777  0.493777  0.493777  0.493777   0.493777  \n",
       "3  0.487160  0.487160  0.487160  0.487160   0.487160  \n",
       "4  0.509512  0.509512  0.509512  0.509512   0.509512  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data = nyc_weather_df.merge(finance_df_norm, on='DATE')\n",
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 4: Feature Engineering\n",
    "\n",
    "Because we are going to be thinking of this in terms of a simple neural network here (like a dense neural network), extend the data by the input data actually being the past $n$ days ($n$ between 1 and 7). In other words the $X$ input should contain a lag of variables you loaded, but lagged by days from 1 through 7. In other words if it hasn't snowed in the past 7 days you will have attributes $[0,0,0,0,0,0,0]$ for yesterday and the preceeding 8 days of no snow, being \"columns\" or dimensions in your input data.\n",
    "\n",
    "One challenge is that for weekend you will not have trading days so you will need to do some data filling. After you \"fatten\" your data, should see if you need all this data. You should normalize all your input variables so that that have an approximate range between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>Rain_intensity</th>\n",
       "      <th>Snow_intensity</th>\n",
       "      <th>Wind_intensity</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>market_volatility_lag_one</th>\n",
       "      <th>market_volatility_lag_two</th>\n",
       "      <th>market_volatility_lag_three</th>\n",
       "      <th>market_volatility_lag_four</th>\n",
       "      <th>market_volatility_lag_five</th>\n",
       "      <th>market_volatility_lag_six</th>\n",
       "      <th>market_volatility_lag_seven</th>\n",
       "      <th>high-low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  PRCP  SNOW  Rain_intensity  Snow_intensity  Wind_intensity  \\\n",
       "0 1992-01-02     0     0               1               0               1   \n",
       "1 1992-01-03     0     0               1               0               1   \n",
       "2 1992-01-06     0     0               1               2               1   \n",
       "3 1992-01-07     1     1               1               2               1   \n",
       "4 1992-01-08     0     0               0               2               1   \n",
       "\n",
       "       Open      High       Low     Close  Adj Close  \\\n",
       "0  0.465631  0.465631  0.465631  0.465631   0.465631   \n",
       "1  0.514483  0.514483  0.514483  0.514483   0.514483   \n",
       "2  0.493777  0.493777  0.493777  0.493777   0.493777   \n",
       "3  0.487160  0.487160  0.487160  0.487160   0.487160   \n",
       "4  0.509512  0.509512  0.509512  0.509512   0.509512   \n",
       "\n",
       "   market_volatility_lag_one  market_volatility_lag_two  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   market_volatility_lag_three  market_volatility_lag_four  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   market_volatility_lag_five  market_volatility_lag_six  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   market_volatility_lag_seven  high-low  \n",
       "0                            0       0.0  \n",
       "1                            0       0.0  \n",
       "2                            0       0.0  \n",
       "3                            0       0.0  \n",
       "4                            0       0.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data['market_volatility_lag_one'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_two'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_three'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_four'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_five'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_six'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data['market_volatility_lag_seven'] = pd.Series(0, index=joined_data.index)\n",
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import datetime\n",
    "\n",
    "def lag_function(num_days, df,x):\n",
    "    for i in range(0, len(df)):\n",
    "        reqDate = df.loc[i, 'DATE'] - datetime.timedelta(days=num_days)\n",
    "        myIdx = df.index[df['DATE'] == reqDate].tolist()\n",
    "        if len(myIdx) > 0: \n",
    "            df.loc[i,x] = df.loc[myIdx[0], 'SNOW']\n",
    "        else:\n",
    "            df.loc[i,x] = 0\n",
    "    return df\n",
    "\n",
    "lag_one_day = partial(lag_function, 1)\n",
    "x = 'market_volatility_lag_one'\n",
    "joined_data= lag_one_day(joined_data,x)\n",
    "\n",
    "lag_two_days = partial(lag_function, 2)\n",
    "x = 'market_volatility_lag_two'\n",
    "joined_data= lag_two_days(joined_data,x)\n",
    "\n",
    "lag_three_days = partial(lag_function, 3)\n",
    "x = 'market_volatility_lag_three'\n",
    "joined_data= lag_three_days(joined_data,x)\n",
    "\n",
    "lag_four_days = partial(lag_function, 4)\n",
    "x = 'market_volatility_lag_four'\n",
    "joined_data= lag_four_days(joined_data,x)\n",
    "\n",
    "lag_five_days = partial(lag_function, 5)\n",
    "x = 'market_volatility_lag_five'\n",
    "joined_data= lag_five_days(joined_data,x)\n",
    "\n",
    "lag_six_days = partial(lag_function, 6)\n",
    "x = 'market_volatility_lag_six'\n",
    "joined_data= lag_six_days(joined_data,x)\n",
    "\n",
    "lag_seven_days = partial(lag_function, 7)\n",
    "x = 'market_volatility_lag_seven'\n",
    "joined_data= lag_seven_days(joined_data,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>Rain_intensity</th>\n",
       "      <th>Snow_intensity</th>\n",
       "      <th>Wind_intensity</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>market_volatility_lag_one</th>\n",
       "      <th>market_volatility_lag_two</th>\n",
       "      <th>market_volatility_lag_three</th>\n",
       "      <th>market_volatility_lag_four</th>\n",
       "      <th>market_volatility_lag_five</th>\n",
       "      <th>market_volatility_lag_six</th>\n",
       "      <th>market_volatility_lag_seven</th>\n",
       "      <th>high-low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0.465631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0.509512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1992-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456550</td>\n",
       "      <td>0.456550</td>\n",
       "      <td>0.456550</td>\n",
       "      <td>0.456550</td>\n",
       "      <td>0.456550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1992-01-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1992-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564981</td>\n",
       "      <td>0.564981</td>\n",
       "      <td>0.564981</td>\n",
       "      <td>0.564981</td>\n",
       "      <td>0.564981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1992-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  PRCP  SNOW  Rain_intensity  Snow_intensity  Wind_intensity  \\\n",
       "0 1992-01-02     0     0               1               0               1   \n",
       "1 1992-01-03     0     0               1               0               1   \n",
       "2 1992-01-06     0     0               1               2               1   \n",
       "3 1992-01-07     1     1               1               2               1   \n",
       "4 1992-01-08     0     0               0               2               1   \n",
       "5 1992-01-09     1     1               2               2               1   \n",
       "6 1992-01-10     1     1               1               2               1   \n",
       "7 1992-01-13     1     0               1               2               1   \n",
       "8 1992-01-14     1     1               1               2               0   \n",
       "9 1992-01-15     1     1               0               2               0   \n",
       "\n",
       "       Open      High       Low     Close  Adj Close  \\\n",
       "0  0.465631  0.465631  0.465631  0.465631   0.465631   \n",
       "1  0.514483  0.514483  0.514483  0.514483   0.514483   \n",
       "2  0.493777  0.493777  0.493777  0.493777   0.493777   \n",
       "3  0.487160  0.487160  0.487160  0.487160   0.487160   \n",
       "4  0.509512  0.509512  0.509512  0.509512   0.509512   \n",
       "5  0.509512  0.509512  0.509512  0.509512   0.509512   \n",
       "6  0.456550  0.456550  0.456550  0.456550   0.456550   \n",
       "7  0.436664  0.436664  0.436664  0.436664   0.436664   \n",
       "8  0.564981  0.564981  0.564981  0.564981   0.564981   \n",
       "9  0.576137  0.576137  0.576137  0.576137   0.576137   \n",
       "\n",
       "   market_volatility_lag_one  market_volatility_lag_two  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          1                          0   \n",
       "5                          0                          1   \n",
       "6                          1                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          1                          0   \n",
       "\n",
       "   market_volatility_lag_three  market_volatility_lag_four  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "5                            0                           0   \n",
       "6                            1                           0   \n",
       "7                            1                           1   \n",
       "8                            0                           1   \n",
       "9                            0                           0   \n",
       "\n",
       "   market_volatility_lag_five  market_volatility_lag_six  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "5                           0                          0   \n",
       "6                           0                          0   \n",
       "7                           0                          1   \n",
       "8                           1                          0   \n",
       "9                           1                          1   \n",
       "\n",
       "   market_volatility_lag_seven  high-low  \n",
       "0                            0       0.0  \n",
       "1                            0       0.0  \n",
       "2                            0       0.0  \n",
       "3                            0       0.0  \n",
       "4                            0       0.0  \n",
       "5                            0       0.0  \n",
       "6                            0       0.0  \n",
       "7                            0       0.0  \n",
       "8                            1       0.0  \n",
       "9                            0       0.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'PRCP', 'SNOW', 'Rain_intensity', 'Snow_intensity',\n",
       "       'Wind_intensity', 'Open', 'High', 'Low', 'Close', 'Adj Close',\n",
       "       'market_volatility_lag_one', 'market_volatility_lag_two',\n",
       "       'market_volatility_lag_three', 'market_volatility_lag_four',\n",
       "       'market_volatility_lag_five', 'market_volatility_lag_six',\n",
       "       'market_volatility_lag_seven', 'high-low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['ELEMENT'].count()\n",
    "joined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 19)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the code for dealing with weekends here\n",
    "joined_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 5: Try out different Models and prediction!\n",
    "\n",
    "Your goal is to predict the volatility in the market, that is the Market High - Market Low your \"Y\" value. For convenience create that column. All of the other columns will help create your \"X\" variables. You can use any of the other variables as predictors. Be careful not use Market High or Market Low as \"X\" variables!\n",
    "\n",
    "Since we are doing a regression problem that means that the last neural net activation will probably be linear and the loss should be Mean Squared Error or root mean squared error or mean absolute error.\n",
    "\n",
    "Try five different models. For each model, please report mse, root mse and mean absolute error.  You can get the training history with:\n",
    "\n",
    "Record the history with:\n",
    "\n",
    "`history = model.fit(X, y, validation_split=0.1)`\n",
    "\n",
    "and get the history for your metrics with:\n",
    "\n",
    "`history.history`\n",
    "\n",
    "For more details, see this tutorial: https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/\n",
    "\n",
    "Also, please note the above tutorial shows you how to include multiple metrics with keras.\n",
    "\n",
    "Then try cross validation with the above metrics. \n",
    "\n",
    "If you've never done cross validation with keras before, please use: https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "\n",
    "The above tutorial will show you how.\n",
    "\n",
    "After running cross validation for each of the metrics you should be able to answer the following questions:\n",
    "\n",
    "Is there overfitting? How do you know?\n",
    "Why do you think certain models worked well and others not as well? \n",
    "How might you improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_data['sub'] = joined_data['High'] - joined_data['Low']\n",
    "features =  ['PRCP', 'SNOW', 'Rain_intensity', 'Snow_intensity',\n",
    "       'Wind_intensity','Adj Close',\n",
    "       'market_volatility_lag_one', 'market_volatility_lag_two',\n",
    "       'market_volatility_lag_three', 'market_volatility_lag_four',\n",
    "       'market_volatility_lag_five', 'market_volatility_lag_six',\n",
    "       'market_volatility_lag_seven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data['high-low'] = joined_data.High - joined_data.Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonali\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.2486 - mean_squared_error: 0.2486\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 113us/sample - loss: 0.0368 - mean_squared_error: 0.0368\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 130us/sample - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 134us/sample - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 127us/sample - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 117us/sample - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 117us/sample - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 119us/sample - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 122us/sample - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 115us/sample - loss: 8.8946e-04 - mean_squared_error: 8.8946e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ef3b61c668>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating out the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = joined_data.loc[:, features].values\n",
    "# Separating out the target\n",
    "#loss=tf.keras.metrics.mean_squared_error\n",
    "y = joined_data.loc[:,['high-low']].values\n",
    "# Standardizing the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "dt_reg = DecisionTreeRegressor(criterion='mse', max_depth=3)    \n",
    "svr_linear = SVR(kernel='linear', C=100, gamma='auto')\n",
    "linear_ridge = Ridge()\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=13, activation= \"relu\"))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "\n",
    "\n",
    "linear_reg.fit(X_train, y_train)\n",
    "dt_reg.fit(X_train, y_train)\n",
    "svr_linear.fit(X_train, y_train)\n",
    "linear_ridge.fit(X_train, y_train)\n",
    "model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regession  mse:0.0\n",
      "linear_regession  rmse:0.0\n",
      "linear_regession  mae:0.0\n",
      "svr_linear  mse:0.0\n",
      "svr_linear  rmse:0.0\n",
      "svr_linear  mae:0.0\n",
      "ann_model  mse:0.0002694670066959924\n",
      "ann_model  rmse:0.016415450243474666\n",
      "ann_model  mae:0.11573107268983944\n"
     ]
    }
   ],
   "source": [
    "models =['linear_regession','svr_linear', 'ann_model']\n",
    "for model_name, model in zip(models,  [linear_reg, svr_linear, model4]):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"{}  mse:{}\".format(model_name, mean_squared_error(y_test,y_pred)))\n",
    "    print(\"{}  rmse:{}\".format(model_name, np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "    print(\"{}  mae:{}\".format(model_name, np.sqrt(mean_absolute_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here mse, rmse and mae for linear regression and svm model is 0 it ran into underfitting problem \n",
    "This can happen if either the model is too simple, or x does not explain y. The latter can have different causes like noise, variables that have an influence but were not observed\n",
    "I will try with differnt models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten\n",
    "\n",
    "def model_one(X_train,y_train):\n",
    "    model_1 = Sequential()\n",
    "    model_1.add(Dense(100,input_dim=13,activation='relu'))\n",
    "    model_1.add(Dense(1, activation='softmax'))\n",
    "    model_1.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "    model_1.fit(X_train,y_train, validation_split= 0.2,epochs=5,batch_size=5)\n",
    "    return model_1\n",
    "\n",
    "def model_two(X_train,y_train):\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(64,input_dim=13,activation='relu'))\n",
    "    model_2.add(Dense(1, activation='softmax'))\n",
    "    model_2.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "    model_2.fit(X_train,y_train, validation_split= 0.2,epochs=5,batch_size=3)\n",
    "    return model_2\n",
    "\n",
    "\n",
    "def model_three(X_train,y_train):\n",
    "    model_3 = Sequential()\n",
    "    model_3.add(Dense(64, input_dim=13, activation='relu'))\n",
    "    model_3.add(Dropout(0.5))   \n",
    "    model_3.add(Dense(1, activation='relu'))\n",
    "    model_3.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "    model_3.fit(X_train,y_train,validation_split= 0.4, epochs=7, batch_size=32)\n",
    "    return model_3\n",
    "\n",
    "def model_four(X_train,y_train):\n",
    "    model_4 = Sequential()\n",
    "    model_4.add(Dense(100, input_dim=13, activation='relu'))\n",
    "    model_4.add(Dense(32, activation='relu'))\n",
    "    model_4.add(Dropout(0.5))\n",
    "    model_4.add(Dense(1, activation='sigmoid'))\n",
    "    model_4.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "    model_4.fit(X_train,y_train, epochs=8, batch_size=10)\n",
    "    return model_4\n",
    "\n",
    "def model_five(X_train,y_train):\n",
    "    model_5 = Sequential()\n",
    "    model_5.add(Dense(64, input_dim=13, activation='relu'))\n",
    "    model_5.add(Dense(32, activation='relu'))\n",
    "    model_5.add(Dense(16, activation='relu'))\n",
    "    model_5.add(Dense(1, activation='sigmoid'))\n",
    "    model_5.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "    model_5.fit(X_train,y_train, epochs=10, batch_size=10)\n",
    "    return model_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 2s 11ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 918us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 124us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "model1 = model_one(X_train,y_train)\n",
    "print(model1.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 8ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 954us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 880us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 2ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 2ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 218us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "model2 = model_two(X_train,y_train)\n",
    "print(model2.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 81 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 10ms/sample - loss: 0.0736 - mean_squared_error: 0.0736 - val_loss: 0.0839 - val_mean_squared_error: 0.0839\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 401us/sample - loss: 0.1313 - mean_squared_error: 0.1313 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 480us/sample - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 451us/sample - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 410us/sample - loss: 0.0489 - mean_squared_error: 0.0489 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 6/7\n",
      "121/121 [==============================] - 0s 402us/sample - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 383us/sample - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 180us/sample - loss: 0.0019 - mean_squared_error: 0.0011\n",
      "[0.0010946755909233116, 0.0010946756]\n"
     ]
    }
   ],
   "source": [
    "model3 = model_three(X_train,y_train)\n",
    "print(model3.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/8\n",
      "202/202 [==============================] - 1s 6ms/sample - loss: 0.1777 - mean_squared_error: 0.1777\n",
      "Epoch 2/8\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.0410 - mean_squared_error: 0.0410\n",
      "Epoch 3/8\n",
      "202/202 [==============================] - 0s 168us/sample - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 4/8\n",
      "202/202 [==============================] - 0s 217us/sample - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 5/8\n",
      "202/202 [==============================] - 0s 226us/sample - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 6/8\n",
      "202/202 [==============================] - 0s 172us/sample - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 7/8\n",
      "202/202 [==============================] - 0s 199us/sample - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 8/8\n",
      "202/202 [==============================] - 0s 179us/sample - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 2.2749e-04 - mean_squared_error: 2.6947e-04\n",
      "[0.0002694670093821033, 0.000269467]\n"
     ]
    }
   ],
   "source": [
    "model4 = model_four(X_train,y_train)\n",
    "print(model4.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 6ms/sample - loss: 0.1592 - mean_squared_error: 0.1592\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.0359 - mean_squared_error: 0.0359\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 171us/sample - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 7.3986e-04 - mean_squared_error: 7.3986e-04\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 176us/sample - loss: 4.6136e-04 - mean_squared_error: 4.6136e-04\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 183us/sample - loss: 3.2711e-04 - mean_squared_error: 3.2711e-04\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 174us/sample - loss: 2.4628e-04 - mean_squared_error: 2.4628e-04\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 1.9093e-04 - mean_squared_error: 1.9093e-04\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 182us/sample - loss: 1.5194e-04 - mean_squared_error: 1.5194e-04\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.0194e-04 - mean_squared_error: 2.0681e-04\n",
      "[0.0002068063203135834, 0.00020680632]\n"
     ]
    }
   ],
   "source": [
    "model5 = model_five(X_train,y_train)\n",
    "print(model5.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 7ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 809us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 803us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 871us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 95us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 2\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 2s 10ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 915us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 192us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 3\n",
      "Train on 121 samples, validate on 81 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 10ms/sample - loss: 0.2901 - mean_squared_error: 0.2901 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 281us/sample - loss: 0.2800 - mean_squared_error: 0.2800 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 291us/sample - loss: 0.1314 - mean_squared_error: 0.1314 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 335us/sample - loss: 0.1925 - mean_squared_error: 0.1925 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 404us/sample - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 6/7\n",
      "121/121 [==============================] - 0s 452us/sample - loss: 0.0634 - mean_squared_error: 0.0634 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 568us/sample - loss: 0.0576 - mean_squared_error: 0.0576 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 119us/sample - loss: 0.0011 - mean_squared_error: 0.0021\n",
      "[0.002146859379375682, 0.0021468594]\n",
      "model 4\n",
      "Train on 202 samples\n",
      "Epoch 1/8\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.1029 - mean_squared_error: 0.1029\n",
      "Epoch 2/8\n",
      "202/202 [==============================] - 0s 374us/sample - loss: 0.0258 - mean_squared_error: 0.0258\n",
      "Epoch 3/8\n",
      "202/202 [==============================] - 0s 413us/sample - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 326us/sample - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 5/8\n",
      "202/202 [==============================] - 0s 281us/sample - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 6/8\n",
      "202/202 [==============================] - 0s 279us/sample - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 7/8\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 8/8\n",
      "202/202 [==============================] - 0s 329us/sample - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.6121e-04 - mean_squared_error: 1.2269e-04\n",
      "[0.0001226944498507781, 0.00012269444]\n",
      "model 5\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 6ms/sample - loss: 0.0956 - mean_squared_error: 0.0956\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 214us/sample - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 233us/sample - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 408us/sample - loss: 7.0970e-04 - mean_squared_error: 7.0970e-04\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 364us/sample - loss: 4.9281e-04 - mean_squared_error: 4.9281e-04\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 3.6813e-04 - mean_squared_error: 3.6813e-04\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 232us/sample - loss: 2.8711e-04 - mean_squared_error: 2.8711e-04\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 227us/sample - loss: 2.2939e-04 - mean_squared_error: 2.2939e-04\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 334us/sample - loss: 1.8748e-04 - mean_squared_error: 1.8748e-04\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.3244e-04 - mean_squared_error: 2.2153e-04\n",
      "[0.00022153129205381607, 0.00022153129]\n",
      "model 1\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 2s 10ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 744us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 726us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 736us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 160us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 2\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 7ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 2ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 117us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 3\n",
      "Train on 121 samples, validate on 81 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 10ms/sample - loss: 0.2112 - mean_squared_error: 0.2112 - val_loss: 0.1517 - val_mean_squared_error: 0.1517\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 354us/sample - loss: 0.1701 - mean_squared_error: 0.1701 - val_loss: 0.1173 - val_mean_squared_error: 0.1173\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 309us/sample - loss: 0.1128 - mean_squared_error: 0.1128 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 347us/sample - loss: 0.0924 - mean_squared_error: 0.0924 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 367us/sample - loss: 0.1127 - mean_squared_error: 0.1127 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 6/7\n",
      "121/121 [==============================] - 0s 341us/sample - loss: 0.0744 - mean_squared_error: 0.0744 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 418us/sample - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 174us/sample - loss: 0.0452 - mean_squared_error: 0.0258\n",
      "[0.025815163172927556, 0.025815165]\n",
      "model 4\n",
      "Train on 202 samples\n",
      "Epoch 1/8\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.1728 - mean_squared_error: 0.1728\n",
      "Epoch 2/8\n",
      "202/202 [==============================] - 0s 206us/sample - loss: 0.0604 - mean_squared_error: 0.0604\n",
      "Epoch 3/8\n",
      "202/202 [==============================] - 0s 194us/sample - loss: 0.0226 - mean_squared_error: 0.0226\n",
      "Epoch 4/8\n",
      "202/202 [==============================] - 0s 207us/sample - loss: 0.0088 - mean_squared_error: 0.0088\n",
      "Epoch 5/8\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 6/8\n",
      "202/202 [==============================] - 0s 202us/sample - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 7/8\n",
      "202/202 [==============================] - 0s 197us/sample - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 8/8\n",
      "202/202 [==============================] - 0s 201us/sample - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 2.7951e-04 - mean_squared_error: 2.5266e-04\n",
      "[0.00025265838713476474, 0.00025265838]\n",
      "model 5\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 6ms/sample - loss: 0.1991 - mean_squared_error: 0.1991\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 248us/sample - loss: 0.0757 - mean_squared_error: 0.0757\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 250us/sample - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 247us/sample - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 188us/sample - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 224us/sample - loss: 9.6595e-04 - mean_squared_error: 9.6595e-04\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 344us/sample - loss: 6.6279e-04 - mean_squared_error: 6.6279e-04\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 310us/sample - loss: 4.9089e-04 - mean_squared_error: 4.9089e-04\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 374us/sample - loss: 3.8132e-04 - mean_squared_error: 3.8132e-04\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 379us/sample - loss: 3.0120e-04 - mean_squared_error: 3.0120e-04\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.0135e-04 - mean_squared_error: 2.5874e-04\n",
      "[0.0002587416184171304, 0.0002587416]\n",
      "model 1\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 8ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 873us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 849us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 885us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 809us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 113us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 2\n",
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 1s 9ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 0s 2ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 112us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 3\n",
      "Train on 121 samples, validate on 81 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 10ms/sample - loss: 0.9966 - mean_squared_error: 0.9966 - val_loss: 0.4119 - val_mean_squared_error: 0.4119\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 587us/sample - loss: 0.8216 - mean_squared_error: 0.8216 - val_loss: 0.3280 - val_mean_squared_error: 0.3280\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 364us/sample - loss: 0.5180 - mean_squared_error: 0.5180 - val_loss: 0.2592 - val_mean_squared_error: 0.2592\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 464us/sample - loss: 0.6467 - mean_squared_error: 0.6467 - val_loss: 0.2030 - val_mean_squared_error: 0.2030\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 346us/sample - loss: 0.4923 - mean_squared_error: 0.4923 - val_loss: 0.1550 - val_mean_squared_error: 0.1550\n",
      "Epoch 6/7\n",
      "121/121 [==============================] - 0s 341us/sample - loss: 0.3150 - mean_squared_error: 0.3150 - val_loss: 0.1163 - val_mean_squared_error: 0.1163\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 303us/sample - loss: 0.2624 - mean_squared_error: 0.2624 - val_loss: 0.0873 - val_mean_squared_error: 0.0873\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 81us/sample - loss: 0.0709 - mean_squared_error: 0.0844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08443720142046611, 0.0844372]\n",
      "model 4\n",
      "Train on 202 samples\n",
      "Epoch 1/8\n",
      "202/202 [==============================] - 1s 5ms/sample - loss: 0.1795 - mean_squared_error: 0.1795\n",
      "Epoch 2/8\n",
      "202/202 [==============================] - 0s 177us/sample - loss: 0.0545 - mean_squared_error: 0.0545\n",
      "Epoch 3/8\n",
      "202/202 [==============================] - 0s 230us/sample - loss: 0.0190 - mean_squared_error: 0.0190\n",
      "Epoch 4/8\n",
      "202/202 [==============================] - 0s 210us/sample - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 5/8\n",
      "202/202 [==============================] - 0s 213us/sample - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 6/8\n",
      "202/202 [==============================] - 0s 196us/sample - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 7/8\n",
      "202/202 [==============================] - 0s 193us/sample - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 8/8\n",
      "202/202 [==============================] - 0s 192us/sample - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 3ms/sample - loss: 2.0638e-04 - mean_squared_error: 1.7456e-04\n",
      "[0.00017455793853264813, 0.00017455794]\n",
      "model 5\n",
      "Train on 202 samples\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 1s 6ms/sample - loss: 0.0797 - mean_squared_error: 0.0797\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 0s 292us/sample - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 0s 297us/sample - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 0s 274us/sample - loss: 9.0436e-04 - mean_squared_error: 9.0436e-04\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 0s 286us/sample - loss: 5.8808e-04 - mean_squared_error: 5.8808e-04\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 0s 309us/sample - loss: 4.2367e-04 - mean_squared_error: 4.2367e-04\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 0s 302us/sample - loss: 3.2312e-04 - mean_squared_error: 3.2312e-04\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 0s 311us/sample - loss: 2.5442e-04 - mean_squared_error: 2.5442e-04\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 0s 272us/sample - loss: 2.0372e-04 - mean_squared_error: 2.0372e-04\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 0s 285us/sample - loss: 1.6646e-04 - mean_squared_error: 1.6646e-04\n",
      "51/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.0031e-04 - mean_squared_error: 1.7278e-04\n",
      "[0.00017278019610481957, 0.0001727802]\n",
      "model 1\n",
      "Train on 162 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "162/162 [==============================] - 1s 8ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "162/162 [==============================] - 0s 856us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "162/162 [==============================] - 0s 928us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "162/162 [==============================] - 0s 926us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "162/162 [==============================] - 0s 846us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 149us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 2\n",
      "Train on 162 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "162/162 [==============================] - 1s 8ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 99us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 3\n",
      "Train on 121 samples, validate on 82 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 9ms/sample - loss: 0.3032 - mean_squared_error: 0.3032 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 483us/sample - loss: 0.4811 - mean_squared_error: 0.4811 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 492us/sample - loss: 0.2531 - mean_squared_error: 0.2531 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 517us/sample - loss: 0.1963 - mean_squared_error: 0.1963 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 514us/sample - loss: 0.1165 - mean_squared_error: 0.1165 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 6/7\n",
      "121/121 [==============================] - 0s 500us/sample - loss: 0.0785 - mean_squared_error: 0.0785 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 502us/sample - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 159us/sample - loss: 8.4028e-04 - mean_squared_error: 0.0016\n",
      "[0.0016278659840463661, 0.0016278661]\n",
      "model 4\n",
      "Train on 203 samples\n",
      "Epoch 1/8\n",
      "203/203 [==============================] - 1s 6ms/sample - loss: 0.0921 - mean_squared_error: 0.0921\n",
      "Epoch 2/8\n",
      "203/203 [==============================] - 0s 272us/sample - loss: 0.0188 - mean_squared_error: 0.0188\n",
      "Epoch 3/8\n",
      "203/203 [==============================] - 0s 281us/sample - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 4/8\n",
      "203/203 [==============================] - 0s 314us/sample - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 5/8\n",
      "203/203 [==============================] - 0s 286us/sample - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 6/8\n",
      "203/203 [==============================] - 0s 281us/sample - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 7/8\n",
      "203/203 [==============================] - 0s 333us/sample - loss: 6.6515e-04 - mean_squared_error: 6.6515e-04\n",
      "Epoch 8/8\n",
      "203/203 [==============================] - 0s 326us/sample - loss: 7.6916e-04 - mean_squared_error: 7.6916e-04\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 7.1472e-05 - mean_squared_error: 7.9679e-05\n",
      "[7.967950048623607e-05, 7.96795e-05]\n",
      "model 5\n",
      "Train on 203 samples\n",
      "Epoch 1/10\n",
      "203/203 [==============================] - 1s 6ms/sample - loss: 0.1021 - mean_squared_error: 0.1021\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 0s 306us/sample - loss: 0.0155 - mean_squared_error: 0.0155\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 0s 286us/sample - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 0s 307us/sample - loss: 9.8083e-04 - mean_squared_error: 9.8083e-04\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 0s 284us/sample - loss: 5.6247e-04 - mean_squared_error: 5.6247e-04\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 0s 306us/sample - loss: 3.9469e-04 - mean_squared_error: 3.9469e-04\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 0s 288us/sample - loss: 2.9635e-04 - mean_squared_error: 2.9635e-04\n",
      "Epoch 8/10\n",
      "203/203 [==============================] - 0s 302us/sample - loss: 2.2936e-04 - mean_squared_error: 2.2936e-04\n",
      "Epoch 9/10\n",
      "203/203 [==============================] - 0s 243us/sample - loss: 1.8316e-04 - mean_squared_error: 1.8316e-04\n",
      "Epoch 10/10\n",
      "203/203 [==============================] - 0s 312us/sample - loss: 1.5179e-04 - mean_squared_error: 1.5179e-04\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.1336e-04 - mean_squared_error: 1.2693e-04\n",
      "[0.00012692887452431023, 0.00012692888]\n",
      "model 1\n",
      "Train on 162 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "162/162 [==============================] - 2s 11ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "162/162 [==============================] - 0s 836us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "162/162 [==============================] - 0s 939us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "162/162 [==============================] - 0s 838us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "162/162 [==============================] - 0s 706us/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 205us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 2\n",
      "Train on 162 samples, validate on 41 samples\n",
      "Epoch 1/5\n",
      "162/162 [==============================] - 1s 7ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 2/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 3/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 4/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 5/5\n",
      "162/162 [==============================] - 0s 1ms/sample - loss: 1.0000 - mean_squared_error: 1.0000 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 123us/sample - loss: 1.0000 - mean_squared_error: 1.0000\n",
      "[1.0, 1.0]\n",
      "model 3\n",
      "Train on 121 samples, validate on 82 samples\n",
      "Epoch 1/7\n",
      "121/121 [==============================] - 1s 10ms/sample - loss: 0.4616 - mean_squared_error: 0.4616 - val_loss: 0.2658 - val_mean_squared_error: 0.2658\n",
      "Epoch 2/7\n",
      "121/121 [==============================] - 0s 520us/sample - loss: 0.5394 - mean_squared_error: 0.5394 - val_loss: 0.2038 - val_mean_squared_error: 0.2038\n",
      "Epoch 3/7\n",
      "121/121 [==============================] - 0s 526us/sample - loss: 0.1435 - mean_squared_error: 0.1435 - val_loss: 0.1580 - val_mean_squared_error: 0.1580\n",
      "Epoch 4/7\n",
      "121/121 [==============================] - 0s 480us/sample - loss: 0.2313 - mean_squared_error: 0.2313 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "Epoch 5/7\n",
      "121/121 [==============================] - 0s 515us/sample - loss: 0.1017 - mean_squared_error: 0.1017 - val_loss: 0.0968 - val_mean_squared_error: 0.0968\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 496us/sample - loss: 0.1178 - mean_squared_error: 0.1178 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 7/7\n",
      "121/121 [==============================] - 0s 495us/sample - loss: 0.0701 - mean_squared_error: 0.0701 - val_loss: 0.0631 - val_mean_squared_error: 0.0631\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 159us/sample - loss: 5.5283e-04 - mean_squared_error: 3.0715e-04\n",
      "[0.00030714584747329357, 0.00030714585]\n",
      "model 4\n",
      "Train on 203 samples\n",
      "Epoch 1/8\n",
      "203/203 [==============================] - 1s 6ms/sample - loss: 0.1977 - mean_squared_error: 0.1977\n",
      "Epoch 2/8\n",
      "203/203 [==============================] - 0s 284us/sample - loss: 0.0350 - mean_squared_error: 0.0350\n",
      "Epoch 3/8\n",
      "203/203 [==============================] - 0s 344us/sample - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 4/8\n",
      "203/203 [==============================] - 0s 346us/sample - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 5/8\n",
      "203/203 [==============================] - 0s 323us/sample - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 6/8\n",
      "203/203 [==============================] - 0s 356us/sample - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 7/8\n",
      "203/203 [==============================] - 0s 334us/sample - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 8/8\n",
      "203/203 [==============================] - 0s 413us/sample - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 2.5133e-04 - mean_squared_error: 2.4360e-04\n",
      "[0.00024360440555028616, 0.0002436044]\n",
      "model 5\n",
      "Train on 203 samples\n",
      "Epoch 1/10\n",
      "203/203 [==============================] - 1s 7ms/sample - loss: 0.1038 - mean_squared_error: 0.1038\n",
      "Epoch 2/10\n",
      "203/203 [==============================] - 0s 218us/sample - loss: 0.0192 - mean_squared_error: 0.0192\n",
      "Epoch 3/10\n",
      "203/203 [==============================] - 0s 261us/sample - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 4/10\n",
      "203/203 [==============================] - 0s 222us/sample - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 5/10\n",
      "203/203 [==============================] - 0s 316us/sample - loss: 7.8198e-04 - mean_squared_error: 7.8198e-04\n",
      "Epoch 6/10\n",
      "203/203 [==============================] - 0s 395us/sample - loss: 4.9936e-04 - mean_squared_error: 4.9936e-04\n",
      "Epoch 7/10\n",
      "203/203 [==============================] - 0s 365us/sample - loss: 3.4771e-04 - mean_squared_error: 3.4771e-04\n",
      "Epoch 8/10\n",
      "203/203 [==============================] - 0s 348us/sample - loss: 2.5251e-04 - mean_squared_error: 2.5251e-04\n",
      "Epoch 9/10\n",
      "203/203 [==============================] - 0s 357us/sample - loss: 1.8749e-04 - mean_squared_error: 1.8749e-04\n",
      "Epoch 10/10\n",
      "203/203 [==============================] - 0s 327us/sample - loss: 1.4432e-04 - mean_squared_error: 1.4432e-04\n",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.1104e-04 - mean_squared_error: 1.1321e-04\n",
      "[0.00011320675315801054, 0.00011320675]\n"
     ]
    }
   ],
   "source": [
    "# implement cross validation here\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#X_np = np.array(X)\n",
    "X_np = np.asarray(X).astype(np.float32)\n",
    "#y_nn = pd.get_dummies(data = y)\n",
    "#y_np = np.array(y_nn)\n",
    "y_np = np.asarray(y).astype(np.float32)\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "for train_index, test_index in kf.split(X_np):\n",
    "   # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train,x_test=X_np[train_index],X_np[test_index]\n",
    "    y_train,y_test=y_np[train_index],y_np[test_index]\n",
    "    #model 1\n",
    "    print('model 1')\n",
    "    model_cv1 = model_one(x_train,y_train)\n",
    "    print(model_cv1.evaluate(x_test,y_test))\n",
    "    \n",
    "    # model 2\n",
    "    print('model 2')\n",
    "    model_cv2 = model_two(x_train,y_train)\n",
    "    print(model_cv2.evaluate(x_test,y_test))\n",
    "    \n",
    "    #model 3\n",
    "    print('model 3')\n",
    "    model_cv3 = model_three(x_train,y_train)\n",
    "    print(model_cv3.evaluate(x_test,y_test))\n",
    "    \n",
    "    #model 4\n",
    "    print('model 4')\n",
    "    model_cv4 = model_four(x_train,y_train)\n",
    "    print(model_cv4.evaluate(x_test,y_test))\n",
    "    \n",
    "    #model 5\n",
    "    print('model 5')\n",
    "    model_cv5 = model_five(x_train,y_train)\n",
    "    print(model_cv5.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 13)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples\n",
      "Epoch 1/5\n",
      "202/202 [==============================] - 0s 275us/sample - loss: 7.6774e-05 - mean_squared_error: 7.6774e-05\n",
      "Epoch 2/5\n",
      "202/202 [==============================] - 0s 140us/sample - loss: 6.3207e-05 - mean_squared_error: 6.3207e-05\n",
      "Epoch 3/5\n",
      " 32/202 [===>..........................] - ETA: 0s - loss: 4.5895e-05 - mean_squared_error: 4.5895e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonali\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 111us/sample - loss: 4.7028e-05 - mean_squared_error: 4.7028e-05\n",
      "Epoch 4/5\n",
      "202/202 [==============================] - 0s 114us/sample - loss: 3.5120e-05 - mean_squared_error: 3.5120e-05\n",
      "Epoch 5/5\n",
      "202/202 [==============================] - 0s 118us/sample - loss: 3.0673e-05 - mean_squared_error: 3.0673e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ef09712f60>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "linear_reg.fit(X_train, y_train)\n",
    "dt_reg.fit(X_train, y_train)\n",
    "svr_linear.fit(X_train, y_train)\n",
    "linear_ridge.fit(X_train, y_train)\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF0BC0ABA8>  mse:0.002580376579494064\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF0BC0ABA8>  rmse:0.05079740721231807\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF0BC0ABA8>  mae:0.17486787747438276\n"
     ]
    }
   ],
   "source": [
    "##model 1\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"{}  mse:{}\".format(model1, mean_squared_error(y_test,y_pred)))\n",
    "print(\"{}  rmse:{}\".format(model1, np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "print(\"{}  mae:{}\".format(model1, np.sqrt(mean_absolute_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  mse:0.0002694670066959924\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  rmse:0.016415450243474666\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  mae:0.11573107268983944\n"
     ]
    }
   ],
   "source": [
    "## model2\n",
    "print(\"{}  mse:{}\".format(model3, mean_squared_error(y_test,y_pred)))\n",
    "print(\"{}  rmse:{}\".format(model3, np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "print(\"{}  mae:{}\".format(model3, np.sqrt(mean_absolute_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  mse:0.0002694670066959924\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  rmse:0.016415450243474666\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3E0D1198>  mae:0.11573107268983944\n"
     ]
    }
   ],
   "source": [
    "## model3\n",
    "print(\"{}  mse:{}\".format(model3, mean_squared_error(y_test,y_pred)))\n",
    "print(\"{}  rmse:{}\".format(model3, np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "print(\"{}  mae:{}\".format(model3, np.sqrt(mean_absolute_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3D9FFA90>  mse:0.0002694670066959924\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3D9FFA90>  rmse:0.016415450243474666\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002EF3D9FFA90>  mae:0.11573107268983944\n"
     ]
    }
   ],
   "source": [
    "## model4\n",
    "print(\"{}  mse:{}\".format(model4, mean_squared_error(y_test,y_pred)))\n",
    "print(\"{}  rmse:{}\".format(model4, np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "print(\"{}  mae:{}\".format(model4, np.sqrt(mean_absolute_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer answer overfitting here and analysis here.  \n",
    "After cross validation data each model's mse imporved but is still has problem of underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusion\n",
    "\n",
    "Conclude with a full report here on what we know now about this problem. How well it does verses baseline, what the best Keras archtecture is, what features should be used, how the data should be cleaned etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code ran into overfitting, it is usefull but it doesnot solved the problem. we can try diffenrt methods to solve these problem like\n",
    "1.Cross Validation, 2. Early stoping, 3. Regularization, 4. Training on more data, 5. Remove features\n",
    "\n",
    "* Reduce your model complexity, which often means reducing the number of parameters.\n",
    "* Regularization, which basically comes down to constraints on the parameters.\n",
    "* Use more training data\n",
    "\n",
    "To improve model performance we can increase the dataset and use Regularizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
